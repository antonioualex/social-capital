{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Economic Connectedness\n",
    "\n",
    "Partial replication on two studies carried out on social capital. The studies appeared in the journal Nature as you can see below:\n",
    "\n",
    "* Chetty, R., Jackson, M.O., Kuchler, T. et al. Social capital I: measurement and associations with economic mobility. Nature 608, 108–121 (2022). [https://doi.org/10.1038/s41586-022-04996-4](https://doi.org/10.1038/s41586-022-04996-4).\n",
    "\n",
    "* Chetty, R., Jackson, M.O., Kuchler, T. et al. Social capital II: determinants of economic connectedness. Nature 608, 122–134 (2022). [https://doi.org/10.1038/s41586-022-04997-3](https://doi.org/10.1038/s41586-022-04997-3).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Geography of Social Capital in the United States\n",
    "\n",
    "Replication of an interactive [Figure 2a of the first paper](https://www.nature.com/articles/s41586-022-04996-4/figures/2).\n",
    "\n",
    "In the figure, the social capital is represented by the Economic Connectedness (EC). Economic Connectedness is the degree to which people with low and high Socioeconomic Status (SES) are friends with each other. More formally, to define EC we start by measuring each individual's $i$ share of friends from SES quantile $Q$:\n",
    "\n",
    "$$ f_{Q, i} = \\frac{[\\textrm{Number of friends in SES quantile}\\ Q]_i}{\\textrm{Total number of friends of}\\ i} $$\n",
    "\n",
    "Then we normalize $f_{Q,i}$ by the share of individuals in the sample who belong to quantile $Q$, $w_Q$ (for example, $w_Q = 0.1$ for deciles) to get the Individual Economic Connectedness (IEC):\n",
    "\n",
    "$$ \\mathrm{IEC}_{Q, i} = \\frac{f_{Q, i}}{w_Q} $$\n",
    "\n",
    "The level of EC in a community $c$ is the defined as the mean level of individual EC of low-SES $L$ (for example, below-median) members of that community, as follows:\n",
    "\n",
    "$$ \\mathrm{EC}_{c} = \\frac{\\sum_{i \\in L \\cap c}\\mathrm{IEC}_i}{N_{Lc}} $$\n",
    "\n",
    "where $N_{Lc}$ is the number of low-SES individuals in community $c$.\n",
    "\n",
    "In the figure and in what follows, the EC is twice the share of friends with above-median SES among people with below-median SES; that follows from the above definitions for $w_Q = 0.5$.\n",
    "\n",
    "The map is constructed using Plotly. The data are displayed per county. When hovering a county, it should display the name of the county and the state it belongs to, the code of the county, and the Economic Connectedness of the county. If there are no data for a particular county, it should be painted with gold, and the economic connectedness should be given as \"NA\".\n",
    "\n",
    "Social capital data source: [Social Capital Atlas Datasets](https://data.humdata.org/dataset/social-capital-atlas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_county = pd.read_csv(\"data/social_capital_county.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we load a GeoJSON file containing the geometry information for US counties, where feature.id is a FIPS (Federal Information Processing Standards) code.\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transforming GeoJSON file with its counties into a dataframe in order to be merged into the main county dataframe (so we fill up our dataframe with the missing counties).\n",
    "df_counties = pd.DataFrame.from_records(counties['features'], columns=['id'] )\n",
    "df_counties.rename(columns={'id': 'county'}, inplace=True)\n",
    "df_counties.county = df_counties.county.apply(lambda x: str(x).zfill(5))\n",
    "data_county.county = data_county.county.apply(lambda x: str(x).zfill(5))\n",
    "data_counties_processed = pd.merge(data_county, df_counties, on='county', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Filling NA values\n",
    "data_counties_processed.ec_county.fillna(value=0, inplace=True)\n",
    "data_counties_processed.county_name.fillna(value='NA', inplace=True)\n",
    "data_counties_processed['economic_connectedness'] = data_counties_processed.ec_county.apply(lambda x : round(x, 2))\n",
    "data_counties_processed['economic_connectedness'] = data_counties_processed.economic_connectedness.apply(lambda x: 'NA' if x==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Categorizing economic_connectedness\n",
    "data_counties_processed['color_space'] = pd.cut(data_counties_processed['ec_county'], [-1, 0, 0.58, 0.67, 0.72, 0.76, 0.81, 0.85, 0.90, 0.97, 1.06, float('inf')])\n",
    "data_counties_processed['color_space'] = data_counties_processed['color_space'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up custom counties and staes through Federal Communications Commission\n",
    "\n",
    "fips_counties = pd.read_csv(\"https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt\", delimiter = \"\\t\")\n",
    "fips_counties = fips_counties.rename(columns= {'Federal Information Processing System (FIPS) Codes for States and Counties':'county'})\n",
    "\n",
    "#######\n",
    "bi_fips = fips_counties['county'].apply(lambda x: str(x).lstrip()[0:5].isdigit())\n",
    "custom_counties = fips_counties[bi_fips]\n",
    "\n",
    "custom_counties['county'] = custom_counties['county'].apply(lambda x: x.lstrip())\n",
    "custom_counties = pd.DataFrame(custom_counties.county.str.split(' ',1).tolist(),\n",
    "                                 columns = ['fips','county'])\n",
    "custom_counties.county = custom_counties.county.apply(lambda x: x.replace(\"County\", \"\").strip())\n",
    "\n",
    "custom_counties.rename(columns= {'fips':'county', 'county':'county_name'}, inplace=True)\n",
    "\n",
    "#######################\n",
    "\n",
    "si_fips = fips_counties['county'].apply(lambda x: x.lstrip()[0:2].isdigit() and not x.lstrip()[0:3].isdigit())\n",
    "custom_states = fips_counties[si_fips]\n",
    "\n",
    "custom_states['county'] = custom_states['county'].apply(lambda x: x.lstrip())\n",
    "custom_states = pd.DataFrame(custom_states.county.str.split(' ',1).tolist(),\n",
    "                                  columns = ['fips','state'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Interactive map creation\n",
    "fig = px.choropleth(\n",
    "                    data_counties_processed,\n",
    "                    geojson=counties,\n",
    "                    locations='county',\n",
    "                    color='color_space',\n",
    "                    color_discrete_map={\n",
    "                        '(-1.0, 0.0]': 'gold',\n",
    "                        '(0.0, 0.58]': 'red',\n",
    "                        '(0.58, 0.67]': 'orangered' ,\n",
    "                        '(0.67, 0.72]': 'lightsalmon' ,\n",
    "                        '(0.72, 0.76]': 'mistyrose',\n",
    "                        '(0.76, 0.81]': 'whitesmoke',\n",
    "                        '(0.81, 0.85]': 'lightblue',\n",
    "                        '(0.85, 0.9]': 'skyblue',\n",
    "                        '(0.9, 0.97]': 'cornflowerblue',\n",
    "                        '(0.97, 1.06]': 'royalblue' ,\n",
    "                        '(1.06, inf]': 'darkblue',\n",
    "                   },\n",
    "                   scope=\"usa\",\n",
    "                   hover_name = 'county_name',\n",
    "                   hover_data={\n",
    "                       'county': True,\n",
    "                       'economic_connectedness': True\n",
    "                   },\n",
    "                   labels={\n",
    "                       'economic_connectedness': 'Economic Connectedness',\n",
    "                       'county': 'county',\n",
    "                       'color_space': 'Economic Connectedness'\n",
    "                   },\n",
    "                   category_orders={\n",
    "                       'color_space': ['(1.06, inf]','(0.97, 1.06]','(0.9, 0.97]','(0.85, 0.9]', '(0.81, 0.85]','(0.76, 0.81]','(0.72, 0.76]','(0.67, 0.72]', '(0.58, 0.67]','(0.0, 0.58]','(-1.0, 0.0]']\n",
    "                   }\n",
    "                  )\n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Economic Connectedness and Outcomes\n",
    "\n",
    "Replication of [Figure 4 of the first paper](nature.com/articles/s41586-022-04996-4/figures/4). The figure is a scatter plot of upward income mobility against economic connectedness (EC) for the 200 most populous US counties. The income mobility is obtained from the [Opportunity Atlas](https://www.nber.org/papers/w25147), whose replication data can be found [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/NKCQM1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reading data from Opportunitly Atlas source file in order to obtain income mobility.\n",
    "county_outcomes = pd.read_csv(\"data/county_outcomes_simple.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting from counties data frame the 200 most populous.\n",
    "top_200_pop_index = data_county['pop2018'].nlargest(200).index\n",
    "top_200_counties_pop = data_county.iloc[top_200_pop_index]\n",
    "top_200_counties_pop = top_200_counties_pop[['county', 'pop2018', 'ec_county']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting and formatting income mobility from county outcomes source file in order to be merged with the 200 most populous counties.\n",
    "county_outcomes_processed = county_outcomes[['state', 'county', 'kfr_pooled_pooled_p25']]\n",
    "county_outcomes_processed.state = county_outcomes_processed.state.apply(lambda x: str(x).zfill(2))\n",
    "county_outcomes_processed.county = county_outcomes_processed.county.apply(lambda x: str(x).zfill(3))\n",
    "county_outcomes_processed['county'] = county_outcomes_processed.state + county_outcomes_processed.county\n",
    "county_outcomes_processed = county_outcomes_processed.drop(['state'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Merging are two tables into one in order to create the lmplot.\n",
    "ec_outcomes = pd.merge(top_200_counties_pop, county_outcomes_processed, on='county', how='left')\n",
    "ec_outcomes = pd.merge(ec_outcomes, custom_counties, on='county', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Storing cities that they are going to be annotated. (Minneapolis and Indianapolis belong to Hennepin and Marion Counties respectively)\n",
    "ec_outcomes_sel_cities= ['New York', 'Salt Lake', 'Hennepin', 'San Francisco', 'Marion']\n",
    "pointed_cities = ec_outcomes.loc[ec_outcomes.county_name.isin(ec_outcomes_sel_cities)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the default theme\n",
    "sns.set_theme()\n",
    "\n",
    "ax = sns.lmplot(x=\"ec_county\", y=\"kfr_pooled_pooled_p25\", data=ec_outcomes, height=5, aspect=1.5)\n",
    "\n",
    "# Setting labels\n",
    "ax.set(xlabel='Economic Connectedness', ylabel='Predicted Household Income Rank \\nfor Children with Parents at 25th Income Percentile')\n",
    "\n",
    "# New York arrow annotation\n",
    "plt.annotate('New York', (pointed_cities.ec_county.loc[pointed_cities.county_name=='New York'], pointed_cities.kfr_pooled_pooled_p25.loc[pointed_cities.county_name=='New York']),( pointed_cities.ec_county.loc[pointed_cities.county_name=='New York'] , pointed_cities.kfr_pooled_pooled_p25.loc[pointed_cities.county_name=='New York'] + 0.08), arrowprops=dict(arrowstyle=\"-|>\", connectionstyle=\"arc3\", lw=1 , color='black'), size=10, ha=\"center\")\n",
    "\n",
    "# Indianapolis arrow annotation\n",
    "plt.annotate('Indianapolis', (pointed_cities.ec_county.loc[pointed_cities.county=='18097'], pointed_cities.kfr_pooled_pooled_p25.loc[pointed_cities.county=='18097']),( pointed_cities.ec_county.loc[pointed_cities.county=='18097'] + 0.18, pointed_cities.kfr_pooled_pooled_p25.loc[pointed_cities.county=='18097'] -0.013), arrowprops=dict(arrowstyle=\"-|>\", connectionstyle=\"arc3\", lw=1 , color='black'), size=10, ha=\"center\")\n",
    "\n",
    "# Salt Lake City arrow annotation\n",
    "plt.annotate('Salt Lake City', (pointed_cities.ec_county.loc[pointed_cities.county_name=='Salt Lake'], pointed_cities.kfr_pooled_pooled_p25.loc[pointed_cities.county_name=='Salt Lake']),( pointed_cities.ec_county.loc[pointed_cities.county_name=='Salt Lake'] , pointed_cities.kfr_pooled_pooled_p25.loc[pointed_cities.county_name=='Salt Lake'] + 0.06), arrowprops=dict(arrowstyle=\"-|>\", connectionstyle=\"arc3\", lw=1 , color='black'), size=10, ha=\"center\")\n",
    "\n",
    "# San Francisco arrow annotation\n",
    "plt.annotate('San Francisco', (pointed_cities.ec_county.loc[pointed_cities.county_name=='San Francisco'], pointed_cities.kfr_pooled_pooled_p25.loc[pointed_cities.county_name=='San Francisco']),( pointed_cities.ec_county.loc[pointed_cities.county_name=='San Francisco'] , pointed_cities.kfr_pooled_pooled_p25.loc[pointed_cities.county_name=='San Francisco'] - 0.08), arrowprops=dict(arrowstyle=\"-|>\", connectionstyle=\"arc3\", lw=1 , color='black'), size=10, ha=\"center\")\n",
    "\n",
    "# Minneapolis arrow annotation\n",
    "plt.annotate('Minneapolis', (pointed_cities.ec_county.loc[pointed_cities.county_name=='Hennepin'], pointed_cities.kfr_pooled_pooled_p25.loc[pointed_cities.county_name=='Hennepin']),( pointed_cities.ec_county.loc[pointed_cities.county_name=='Hennepin'] + 0.12 , pointed_cities.kfr_pooled_pooled_p25.loc[pointed_cities.county_name=='Hennepin'] - 0.06), arrowprops=dict(arrowstyle=\"-|>\", connectionstyle=\"arc3\", lw=1 , color='black'), size=10, ha=\"center\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Upward Income Mobility, Economic Connectedness, and Median House Income\n",
    "\n",
    "Replication of [Figure 6 of the first paper](https://www.nature.com/articles/s41586-022-04996-4/figures/6). The figure is a scatter plot of economic connectedness (EC) against median household income. The color of the dots corresponds to the child's income rank in adulthood given that the parents' income is in the 25th percentile. The colors correspond to five intervals, which are the quintiles dividing our data.\n",
    "\n",
    "Used data from replication package of the papers with data from the Social Capital Atlas Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reading social capital data by zip code.\n",
    "data_zip = pd.read_csv(\"data/social_capital_zip.csv\")\n",
    "zip_covariates = pd.read_stata(\"data/zip_covariates.dta\", columns=['zip', 'kfr_pooled_pooled_p25','med_inc_2018'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting and formatting zip and economic connectedness from our dataset.\n",
    "ec_zip = data_zip[['zip','ec_zip']]\n",
    "ec_zip.zip = ec_zip.zip.apply(lambda x: str(x).zfill(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Formatting zip code in order to be ready for merge\n",
    "zip_covariates.zip = zip_covariates.zip.apply(lambda x: str(x).zfill(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Merging tables from replication package and social capital\n",
    "merged_zips = pd.merge(ec_zip, zip_covariates, on='zip', how='left')\n",
    "\n",
    "# Dropping NA values\n",
    "merged_zips = merged_zips.dropna()\n",
    "\n",
    "# Formating median income column\n",
    "merged_zips.med_inc_2018 = merged_zips.med_inc_2018.apply(lambda x: int(x))\n",
    "\n",
    "# Keeping data above 30.000 and belove 100.000 median income\n",
    "merged_zips = merged_zips.loc[merged_zips.med_inc_2018 <= 100000]\n",
    "merged_zips = merged_zips.loc[merged_zips.med_inc_2018 >= 30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Upward Mobility column in order to bin kfr_pooled_pooled_p25 intervals\n",
    "merged_zips['Upward Mobility'] = pd.cut(merged_zips['kfr_pooled_pooled_p25'], [0,0.38,0.41,0.44,0.48,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('dark')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 7)})\n",
    "\n",
    "palette = [\"#FD1C03\", \"#FFAE42\", \"#FFF8DC\", \"#3BB9FF\", \"#00008B\"]\n",
    "\n",
    "g = sns.scatterplot(x='med_inc_2018', y='ec_zip', data=merged_zips, hue='Upward Mobility',\n",
    "                    palette=sns.color_palette(palette, 5))\n",
    "\n",
    "handles, labels = g.get_legend_handles_labels()\n",
    "a = g.legend(reversed(handles), reversed(labels) , title = \"Upward Mobility\", loc=\"lower right\")\n",
    "\n",
    "g.set(xlabel='Median Household Income in ZIP Code (US$)', ylabel='Economic Connectedness')\n",
    "\n",
    "a.texts[0].set_text(\" >48\")\n",
    "a.texts[1].set_text(\"44 - 48\")\n",
    "a.texts[2].set_text(\"41 - 44\")\n",
    "a.texts[3].set_text(\"38 - 41\")\n",
    "a.texts[4].set_text(\" <38\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Friending Bias and Exposure by High School\n",
    "\n",
    "Replication of [Figure 5a of the second paper](https://www.nature.com/articles/s41586-022-04997-3/figures/5). The figure depicts the share of students with high parental Socioeconomic Status (SES) against the friending bias of students of low parental SES, with data from the Social Capital Atlas Datasets.\n",
    "\n",
    "Note that in order to get the share of high-parental-SES students, which is the $x$-axis, we took the mean exposure to high-parental-SES individuals by high school and divide it by two. That is because the mean exposure to high-parental-SES individuals by high schools is defined as two times the average share of high parental-SES individuals within three birth cohorts, averaged over low-parental-SES users.\n",
    "\n",
    "Note also that both $x$ and $y$ axis are percentages and the $y$ axis is reversed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reading data for social capital high schools\n",
    "data_high_school = pd.read_csv(\"data/social_capital_high_school.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Mean exposure to high parental SES individuals and divide it by two\n",
    "data_high_school['exposure_parent_ses_hs'] = data_high_school['exposure_parent_ses_hs'].apply(lambda x: (x/2)*100)\n",
    "data_high_school['bias_parent_ses_hs'] = data_high_school['bias_parent_ses_hs'].apply(lambda x: x*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up school to be annotated\n",
    "annotated_high_schools = ['00941729', '060474000432', '170993000942',\n",
    "                          '170993001185', '170993003989', '171449001804',\n",
    "                          '250327000436', '360009101928', '370297001285',\n",
    "                          '483702004138', '250843001336', '062271003230',\n",
    "                          '010237000962', '00846981', '00852124']\n",
    "#\n",
    "friend_bias_expo = data_high_school[['exposure_parent_ses_hs','bias_parent_ses_hs']].dropna()\n",
    "\n",
    "# Getting cells with specific high school id\n",
    "annotations = data_high_school.loc[data_high_school['high_school'].isin(annotated_high_schools)]\n",
    "annotations = annotations[['exposure_parent_ses_hs','bias_parent_ses_hs', 'high_school', 'high_school_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to create annotation. It takes as inputs a dataframe, pyplot instance, and x, y text coords.\n",
    "def create_annotation(df, plt, x_text_cord, y_text_cord):\n",
    "    plt.annotate(df.high_school_name.iloc[0], (df.exposure_parent_ses_hs.iloc[0], df.bias_parent_ses_hs.iloc[0]),( df.exposure_parent_ses_hs.iloc[0] + x_text_cord, df.bias_parent_ses_hs.iloc[0] - y_text_cord), bbox=dict(facecolor='white',alpha=0.8), arrowprops=dict(arrowstyle=\"-|>\", connectionstyle=\"arc3\", lw=1 , color='cyan'), size=10, ha=\"center\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = sns.scatterplot(data=friend_bias_expo, x=\"exposure_parent_ses_hs\", y=\"bias_parent_ses_hs\", alpha=0.4, color='black', linewidth=0)\n",
    "\n",
    "# Reversing y axis\n",
    "a.invert_yaxis()\n",
    "\n",
    "phillips_exeter_academy = annotations.loc[annotations.high_school_name=='Phillips Exeter Academy']\n",
    "bishop_gorman_hs = annotations.loc[annotations.high_school_name=='Bishop Gorman HS']\n",
    "dalton_school = annotations.loc[annotations.high_school_name=='Dalton School']\n",
    "john_l_magnet_school = annotations.loc[annotations.high_school_name=='John L Leflore Magnet School']\n",
    "berkeley_hs = annotations.loc[annotations.high_school_name=='Berkeley HS']\n",
    "north_hollywood = annotations.loc[annotations.high_school_name=='North Hollywood Sr HS']\n",
    "lane_technical = annotations.loc[annotations.high_school_name=='Lane Technical HS']\n",
    "lincoln_park = annotations.loc[annotations.high_school_name=='Lincoln Park HS']\n",
    "payton_college = annotations.loc[annotations.high_school_name=='Payton College Preparatory HS']\n",
    "evanston_twp = annotations.loc[annotations.high_school_name=='Evanston Twp HS']\n",
    "cambridge_rindge = annotations.loc[annotations.high_school_name=='Cambridge Rindge And Latin']\n",
    "new_bedford = annotations.loc[annotations.high_school_name=='New Bedford HS']\n",
    "brooklyn_technical = annotations.loc[annotations.high_school_name=='Brooklyn Technical HS']\n",
    "west_charlotte = annotations.loc[annotations.high_school_name=='West Charlotte HS']\n",
    "lake_highlands = annotations.loc[annotations.high_school_name=='Lake Highlands HS']\n",
    "\n",
    "a.set(xlabel='Share of high-parental-SES students (%)', ylabel='Friending bias among low-parental-SES students (%)')\n",
    "\n",
    "create_annotation(phillips_exeter_academy, plt, 0.5, 5 )\n",
    "sns.scatterplot(data= phillips_exeter_academy, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(bishop_gorman_hs, plt, 4.2, -4.3 )\n",
    "sns.scatterplot(data= bishop_gorman_hs, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(dalton_school, plt, -0.2, 4)\n",
    "sns.scatterplot(data= dalton_school, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(john_l_magnet_school, plt, 2.2, -3.3)\n",
    "sns.scatterplot(data= john_l_magnet_school, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(berkeley_hs, plt, -0.2, 1.3)\n",
    "sns.scatterplot(data= berkeley_hs, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(north_hollywood, plt, -13.2, -3.3)\n",
    "sns.scatterplot(data= north_hollywood, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(lane_technical, plt, 5.2, 4.6)\n",
    "sns.scatterplot(data= lane_technical, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(lincoln_park, plt, 1.2, -9)\n",
    "sns.scatterplot(data= lincoln_park, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(payton_college, plt, 0, 12.1)\n",
    "sns.scatterplot(data= payton_college, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(evanston_twp, plt, 7, -1)\n",
    "sns.scatterplot(data= evanston_twp, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(cambridge_rindge, plt, 17, -1)\n",
    "sns.scatterplot(data= cambridge_rindge, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(new_bedford, plt, -2, -4)\n",
    "sns.scatterplot(data= new_bedford, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(brooklyn_technical, plt, -4, 3)\n",
    "sns.scatterplot(data= brooklyn_technical, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(west_charlotte, plt, -0.51, 4)\n",
    "sns.scatterplot(data= west_charlotte, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "create_annotation(lake_highlands, plt, 4.51, 2)\n",
    "sns.scatterplot(data= lake_highlands, x= 'exposure_parent_ses_hs', y= 'bias_parent_ses_hs', color=\"cyan\", linewidth=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Friending Bias vs. Racial Diversity\n",
    "\n",
    "Replication of [Extended Data Figure 3](https://www.nature.com/articles/s41586-022-04997-3/figures/9) of the second paper. The figure depicts friending bias against racial diversity. Racial diversity is defined by the [Herfindahl-Hirschman Index (HHI)](https://en.wikipedia.org/wiki/Herfindahl%E2%80%93Hirschman_index), borrowed from investing. Translated here, it is $ 1−\\sum_{i}{s_i}^2$, where $s_i$ is the fraction of race/ethnicity $i$ (Black, White, Asian, Hispanic, Native American).\n",
    "\n",
    "The figure contains two scatter plots with their respective regression lines, one for college data and the other for neighborhood data. Each of the two plots displays binned data (that's why you don't see loads of dots and diamonds). The bins are produced by dividing the $x$-axis into ventiles (i.e., 5 percentile point bins); then we plot the mean of the $y$-axis variable against the appropriate mean of the $x$-axis variable in each ventile.\n",
    "\n",
    "The mean of the $x$-axis variable, the HHI index, is the weighted mean of HHI:\n",
    "\n",
    "* For the college plot, the weights are given by the mean number of students per cohort.\n",
    "\n",
    "* For the neighborhood plot, the weights are given by the number of children with below-national-median parental household income.\n",
    "\n",
    "The $y$-axis variable:\n",
    "\n",
    "* For the college plot, it is the mean of the college friending bias.\n",
    "\n",
    "* For the neighborhood plot, it is the mean of the neighborhood friending bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reading social capital, zip covariates and college characteristics data\n",
    "social_capital_college = pd.read_csv(\"data/social_capital_college.csv\")\n",
    "social_capital_zip = pd.read_csv(\"data/social_capital_zip.csv\")\n",
    "college_characteristics = pd.read_stata(\"data/college_characteristics.dta\")\n",
    "zip_covariates = pd.read_stata(\"data/zip_covariates.dta\")\n",
    "# social_capital_zip = pd.read_csv(\"Q5_files/scz.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Formating social capital df and zip covariates df in order to be merged\n",
    "social_capital_zip['zip'] = social_capital_zip['zip'].apply(lambda x: str(x).zfill(5))\n",
    "zip_covariates['zip'] = zip_covariates['zip'].apply(lambda x: str(x).zfill(5))\n",
    "zip_characteristics_merged = pd.merge(social_capital_zip, zip_covariates, on=['zip', 'num_below_p50'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing racial diversity\n",
    "zip_characteristics_merged['hhi'] = zip_characteristics_merged.apply(lambda x: 1 - (x.share_white_2018 ** 2 + x.share_black_2018 ** 2+ x.share_natam_2018 ** 2 + x.share_asian_2018 ** 2 +  x.share_hispanic_2018 ** 2), axis=1)\n",
    "zip_characteristics_merged['weighted_hhi'] = zip_characteristics_merged.num_below_p50 * zip_characteristics_merged.hhi\n",
    "zip_characteristics_merged = zip_characteristics_merged[['zip', 'num_below_p50', 'nbhd_bias_zip', 'hhi', 'weighted_hhi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating binned data\n",
    "zip_characteristics_merged['percentile_5'] = pd.qcut(zip_characteristics_merged.hhi,20)\n",
    "zip_characteristics_merged['weighted_hhi_mean_zip'] = zip_characteristics_merged.groupby('percentile_5')['hhi'].transform('mean')\n",
    "zip_characteristics_merged['bias_mean_zip']= zip_characteristics_merged.groupby('percentile_5')['nbhd_bias_zip'].transform('mean')\n",
    "zip_binned_data = zip_characteristics_merged[['bias_mean_zip','weighted_hhi_mean_zip','percentile_5']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "social_capital_college.college.max()\n",
    "college_characteristics.college.max()\n",
    "#out 7 digits for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Formatting social capital college and college characteristics\n",
    "# Maximum integer digits of college id is 7.\n",
    "social_capital_college.college = social_capital_college.college.apply(lambda x: str(x).zfill(7))\n",
    "college_characteristics.college = college_characteristics.college.apply(lambda x: str(x).zfill(7))\n",
    "merged_college_characteristics = pd.merge(social_capital_college, college_characteristics, on=['college', 'mean_students_per_cohort'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing racial diversity\n",
    "frac_black = merged_college_characteristics.black_share_fall_2000\n",
    "frac_hispanic = merged_college_characteristics.hisp_share_fall_2000\n",
    "frac_asian = merged_college_characteristics.asian_or_pacific_share_fall_2000\n",
    "frac_white = 1 - frac_black - frac_hispanic - frac_asian\n",
    "merged_college_characteristics['hhi'] = 1 - (frac_white ** 2 + frac_black ** 2 + frac_asian ** 2 + frac_hispanic **2)\n",
    "merged_college_characteristics['weighted_spc'] = merged_college_characteristics.mean_students_per_cohort * merged_college_characteristics.hhi\n",
    "merged_college_characteristics = merged_college_characteristics[['college','bias_own_ses_college', 'mean_students_per_cohort', 'hhi', 'weighted_spc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating binned data\n",
    "merged_college_characteristics['percentile_5'] = pd.qcut(merged_college_characteristics.hhi,20)\n",
    "merged_college_characteristics['weighted_hhi_mean_col'] = merged_college_characteristics.groupby('percentile_5')['hhi'].transform('mean')\n",
    "merged_college_characteristics['bias_mean_col']= merged_college_characteristics.groupby('percentile_5')['bias_own_ses_college'].transform('mean')\n",
    "col_binned_data = merged_college_characteristics[['bias_mean_col','weighted_hhi_mean_col','percentile_5']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Merging college and zip binned data\n",
    "binned_data = pd.merge(col_binned_data, zip_binned_data, how='outer', on='percentile_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the default theme\n",
    "sns.set_theme()\n",
    "# draw regplot\n",
    "sns.regplot(x = \"weighted_hhi_mean_zip\",\n",
    "            y = \"bias_mean_zip\",\n",
    "            data = binned_data,\n",
    "            scatter_kws={\"color\": \"darkorange\"}, line_kws={\"color\": \"darkorange\"},\n",
    "            dropna = True)\n",
    "\n",
    "# draw regplot\n",
    "ax = sns.regplot(x = \"weighted_hhi_mean_col\",\n",
    "            y = \"bias_mean_col\",\n",
    "            data = binned_data,\n",
    "            marker=\"D\",\n",
    "            scatter_kws={\"color\": \"cornflowerblue\"}, line_kws={\"color\": \"cornflowerblue\"},\n",
    "            dropna = True\n",
    "            )\n",
    "\n",
    "\n",
    "ax.set_xlabel('Racial Diversity (Herfindahl-Hirschman Index) in Group',fontsize=9)\n",
    "ax.set_ylabel('Friending Bias among Low-Ses Individuals (%)',fontsize=9)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
